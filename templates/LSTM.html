<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8"/>
    <title>LSTM</title>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <link rel="stylesheet" href="../static/style.css" type="text/css"/>
</head>
<body>
    <aside>
        <form action={{ url_for('about') }}>
            <button class="button">Вернуться на страницу с моделями</button>
        </form>
    </aside>
    <main>
        <h1>LSTM - сети долгой краткосрочной памяти</h1>
        <p>
          Для задач в предсказании и классификации событий на временном ряду,
          считается классическим решением применение рекуррентных нейронных
          сетей. Но у обычных рекуррентных нейронных сетей может наблюдаться
          проблема долгосрочной памяти: вне зависимости оттого, насколько важна
          была информация, её вес в процессе большого количества итераций может
          сильно уменьшится, или она вовсе может пропасть.
        </p>
        <p>
          Для решения данной проблемы в 1997 году Зеппом Хохрайтер и
          Юргеном Шмидхубером была предложена долгая краткосрочная память (Long
          short-term memory; LSTM) – особая разновидность архитектуры рекуррентных
          нейронных сетей, способная к обучению долговременным зависимостям.
        </p>
        <p>
          LSTM разработаны специально, чтобы избежать проблемы
          долговременной зависимости. Запоминание информации на долгие периоды
          времени – это их обычное поведение. Ключевой компонент LSTM – это
          состояние ячейки – горизонтальная линия, проходящая по верхней части
          схемы. Состояние ячейки напоминает конвейерную ленту. Она проходит
          напрямую через всю цепочку, участвуя лишь в нескольких линейных
          преобразованиях. Информация может легко течь по ней, не подвергаясь
          изменениям. Тем не менее, LSTM может удалять информацию из состояния
          ячейки; этот процесс регулируется структурами, называемыми фильтрами.
          Фильтры позволяют пропускать информацию на основании некоторых
          условий. Они состоят из слоя сигмоидальной нейронной сети и операции
          поточечного умножения.
        </p>

        <h2>Схема LSTM</h2>
        <img src="../static/LSTM.png" alt="LSTM">
        <p>
          Во-первых, по «трубам» этой схемы текут вектора. Входное слово X(t) в синем кружочке —
          в виде вектора, в стрелочках — вектор, все операции — с векторами.
          В желтых кирпичах — слой нейросети. Напомним: это значит, что там спрятаны
          три операции: сначала входной вектор умножается на матрицу весов слоя (которую
          нейросеть вырабатывает в ходе тренировки), к произведению прибавляется сдвиг (bias),
          наконец, вектор-сумма поэлементно проходит через функцию активации нейронов: сигмоиду
          или гиперболический тангенс. Их графики вы видели выше.
          Посимвольная операция означает, что что каждый элемент вектора по отдельности терпит
          какие-то изменения (как с функцией tanh), а «склеивание» из векторов [1, 2] и
          [3, 4] дает один вектор [1, 2, 3, 4].
        </p>
    </main>
</body>
</html>
