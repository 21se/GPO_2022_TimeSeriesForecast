<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8"/>
    <title>TCN</title>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <link rel="stylesheet" href="../static/style.css" type="text/css"/>
</head>
<body>
    <aside>
        <form action={{ url_for('about') }}>
          <button class="button">Вернуться на страницу с моделями</button>
        </form>
    </aside>
    <main>
        <h1>TCN - временные свёрточные сети</h1>
        <p>
            Сверточные нейронные сети обычно связаны с задачами классификации
            изображений, они являются ценными инструментами для моделирования и
            прогнозирования последовательности при правильных модификациях. TCN
            состоит из расширенных причинно-следственных одномерных сверточных
            слоев с одинаковой входной и выходной длиной, и данная архитектура почти
            не зависит от размера исходных данных.
        </p>
        <p>
            Архитектура TCN не только более точна, чем типичные рекурсивные сети, такие как LSTM и GRU, но также проще и
            понятнее. Следовательно, это может быть отправной точкой для лучшего метода применения глубоких сетей к
            последовательностям.
        </p>
        <p>
            Ниже представлена структура энкодера-декодера. Наиболее критические вопросы решаются следующим образом: TCN может
            взять ряд любой длины и на выходе получить ту же самую длину. Казуальная (casual) свертка используется там, где
            присутствует полностью сверточная одномерная архитектура сети. Ключевой характеристикой является то, что выходное
            значение в момент времени t свертывается только с теми элементами, которые произошли по времени до него.
        </p>

        <h2>Схема TCN</h2>
        <img src="../static/TCN.png" width="50%" height="50%" alt="TCN">

        <h2>Преимущества</h2>
        <ul>
            <li>
                Параллельность. Когда дается предложение, TCN может обрабатывать предложение параллельно, без необходимости в
                последовательной обработке, такой как RNN.
            </li>
            <li>
                Гибкое восприимчивое поле. Размер воспринимающего поля TCN определяется количеством слоев, размером ядра свертки
                и коэффициентом расширения. Его можно гибко настраивать под разные задачи и разные характеристики.
            </li>
            <li>
                Стабильный градиент. RNN часто имеет проблему исчезновения градиента и взрывного роста градиента, который в
                основном вызван совместным использованием параметров в разные периоды времени.Как и традиционные сверточные
                нейронные сети, TCN не имеет проблемы исчезновения и взрыва градиента.
            </li>
            <li>
                Меньше памяти. RNN необходимо сохранять информацию о каждом шаге, когда он используется, что будет занимать
                большой объем памяти.Сверточное ядро ​​TCN совместно используется на одном уровне, и использование памяти ниже.
            </li>
            <br>
        </ul>

        <h2>Недостатки</h2>
        <ul>
            <li>
                TCN может не обладать такой высокой адаптируемостью при трансфертном обучении. Это связано с тем, что в разных
                полях объем исторической информации, необходимой для прогнозирования модели, может быть разным. Следовательно,
                при переносе модели из задачи, требующей меньшего количества информации в памяти, в задачу, требующую большего
                объема памяти, TCN может работать плохо, потому что ее принимающее поле недостаточно велико.
            </li>
            <li>
                TCN, описанный в документе, по-прежнему является односторонней структурой. В таких задачах, как распознавание
                речи и синтез речи, чистая односторонняя структура по-прежнему весьма полезна. Однако в большинстве текстов
                используется двусторонняя структура.Конечно, TCN можно легко расширить до двусторонней структуры, вместо
                использования каузальной свертки, просто используйте традиционную структуру свертки.
            </li>
            <li>
                В конце концов, TCN - это вариант сверточной нейронной сети. Хотя использование расширенной свертки может
                расширить воспринимающее поле, оно все же ограничено. По сравнению с Transformer соответствующая информация
                может иметь любую длину. Захватываемые характеристики все же немного хуже. Применение TCN в тексте еще предстоит
                проверить.
            </li>
        </ul>
    </main>
</body>
</html>
